{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_IV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pxjb3SThkNA",
        "colab_type": "text"
      },
      "source": [
        "## Assignment IV\n",
        "### Thinning\n",
        "\n",
        "The purpose of this assignment is to implement thinning. There is one output for this implementation, the thinned image.\n",
        "\n",
        "Firstly, we import the mount the google drive colab importing its related library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S2sSyhBHMBv",
        "colab_type": "code",
        "outputId": "13b66bba-ce39-4271-fe7e-8ddac8517522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kmOGcYhiSMn",
        "colab_type": "text"
      },
      "source": [
        "Afterwards, the directory is changed to the folder in which the Test Images are stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07vHWZU-HY-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir(\"/content/gdrive/My Drive/BasicAlgorithmsforDigitalImaging/Lab4\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkDioTDSidk_",
        "colab_type": "text"
      },
      "source": [
        "Once this is done, the next step is to import the requirements for the implementation. They are OpenCV library cv2, numpy, cv2_imshow and time library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh8JR44EAztN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjr6M1gdi6uG",
        "colab_type": "text"
      },
      "source": [
        "Finally, the implementation is shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmaxiKttLLFf",
        "colab_type": "code",
        "outputId": "68413821-1b81-4905-a9c3-8c494cd41a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "np.seterr(over='ignore')\n",
        "\n",
        "# Loads an image.\n",
        "src = cv.imread(\"TestImages/all_png/csiga.png\", cv.IMREAD_GRAYSCALE)\n",
        "    \n",
        "# Check if image is loaded correctly.\n",
        "if src is None:\n",
        "  print ('Error opening image!')  \n",
        "  \n",
        "else:\n",
        "  # Show the source image.\n",
        "  # cv2_imshow(src)\n",
        "  \n",
        "  # Convert the previous grayscale image into a binary one.\n",
        "  ret,thresh_img = cv.threshold(src,127,255,cv.THRESH_BINARY)\n",
        "  cv2_imshow(thresh_img)\n",
        "\n",
        "  # Define row length and column length, as they will be widely used during the \n",
        "  # program.\n",
        "  row_length = src.shape[0]\n",
        "  col_length = src.shape[1]\n",
        "  \n",
        "  # Define the target image.\n",
        "  target = np.zeros((row_length,col_length))\n",
        "  \n",
        "  ## THINNING ALGORITHM\n",
        "  # Start measuring the execution time for Thinning algorithm.\n",
        "  start = time.time()\n",
        "  \n",
        "  # Set target1 and target2 images equal to the binary image previously defined.\n",
        "  target2 = thresh_img\n",
        "  target1 = thresh_img\n",
        "  \n",
        "  # Initialize the variable n_del to a number different to zero.\n",
        "  n_del = 1\n",
        "  \n",
        "  while n_del != 0:\n",
        "    \n",
        "    n_del = 0\n",
        "    target1 = target2\n",
        "    \n",
        "    for i in range(2, src.shape[0] - 1):\n",
        "      for j in range(2, src.shape[1] - 1):\n",
        "\n",
        "        # Labelling neighbours.\n",
        "        p = [target1[i-1,j], target1[i-1,j-1], target1[i,j-1], target1[i+1,j-1],\n",
        "            target1[i+1,j], target1[i+1,j+1], target1[i,j+1], target1[i-1,j+1],\n",
        "            target1[i-1,j]]\n",
        "      \n",
        "        # Labelling the upper neighbour.\n",
        "        p2 = [target1[i-2,j], target1[i-2,j-1], target1[i-1,j-1], target1[i,j-1],\n",
        "            target1[i,j], target1[i,j+1], target1[i-1,j+1], target1[i-2,j+1],\n",
        "            target1[i-2,j]]\n",
        "      \n",
        "        # Labelling the left neighbour.\n",
        "        p4 = [target1[i-1,j-1], target1[i-1,j-2], target1[i,j-2], target1[i+1,j-2],\n",
        "            target1[i+1,j-1], target1[i+1,j], target1[i,j], target1[i-1,j],\n",
        "            target1[i-1,j-1]]\n",
        "      \n",
        "        # Compute the non-zero neighbours. \n",
        "        nz = 0\n",
        "        for k in range(8):\n",
        "          if p[k] == 0:\n",
        "            nz = nz + 1\n",
        "      \n",
        "        # Compute the number of zero to non-zero transitions of actual pixel.\n",
        "        tr1 = 0\n",
        "        for k in range(8):\n",
        "          if p[k] == 255 and p[k+1] == 0:\n",
        "            tr1 = tr1 + 1\n",
        "      \n",
        "        # Compute the number of zero to non-zero transitions of upper pixel.\n",
        "        tr2 = 0\n",
        "        for k in range(8):\n",
        "          if p2[k] == 255 and p2[k+1] == 0:\n",
        "            tr2 = tr2 + 1\n",
        "          \n",
        "        # Compute the number of zero to non-zero transitions of left pixel.\n",
        "        tr4 = 0\n",
        "        for k in range(8):\n",
        "          if p4[k] == 255 and p4[k+1] == 0:\n",
        "            tr4 = tr4 + 1\n",
        "      \n",
        "        # Change from object to ground the actual pixel in target2 if following\n",
        "        # conditions are fulfilled.\n",
        "        if (target2[i][j] == 0) and (2 <= nz <= 6) and (tr1 == 1) and (p[0] == 255 or p[2] == 255 or p[4] == 255  or tr2 != 1) and (p[0] == 255 or p[2] == 255 or p[6] == 255  or tr4 != 1):\n",
        "          target2[i][j] = 255\n",
        "          n_del = n_del + 1\n",
        "  \n",
        "  # Stop measuring the execution time for Thinning algorithm.\n",
        "  last = time.time()\n",
        "  \n",
        "  # Show the image after applying the Thinning algorithm.\n",
        "  cv2_imshow(target2)\n",
        "\n",
        "  # Print out the execution time of the Thinning algorithm.\n",
        "  print(\"The time needed to apply thinning is \" + str(last - start) + \" seconds.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAHmElEQVR4nO1d25bjKAw0c/L/v8w+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\nTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7FC1B930A898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAGgElEQVR4nO1d27ajIAyFWf3/X2Ye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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7FC1B930A940>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The time needed to apply thinning is 22.879061222076416 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}